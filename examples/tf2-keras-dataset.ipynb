{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/PIL/Image.py:116: RuntimeWarning: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: 6.0.0.post0\n",
      "Pillow version: 6.1.0\n",
      "  warnings.warn(str(v), RuntimeWarning)\n",
      "/root/miniconda3/lib/python3.5/site-packages/PIL/Image.py:116: RuntimeWarning: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: 6.0.0.post0\n",
      "Pillow version: 6.1.0\n",
      "  warnings.warn(str(v), RuntimeWarning)\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager Execution: True\n",
      "TensorFlow version: 2.0.0-beta1\n",
      "Eager execution is: True\n",
      "Keras version: 2.2.4-tf\n",
      "Running on CPU\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install --user --upgrade pip\n",
    "# !pip install --user -q tensorflow==2.0.0-alpha0\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "print(\"Eager Execution: {}\".format(tf.executing_eagerly()))\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution is: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))\n",
    "\n",
    "# Install a temporary patch to enable a few extra TF 2.0 upgrades. This piece will be removed soon.\n",
    "\n",
    "from tensorflow.python.ops import control_flow_util\n",
    "control_flow_util.ENABLE_CONTROL_FLOW_V2 = True\n",
    "\n",
    "#@tf.function\n",
    "var = tf.Variable([3, 3])\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print('Running on GPU')\n",
    "    print('GPU #0?')\n",
    "    print(var.device.endswith('GPU:0'))\n",
    "else: \n",
    "    print('Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Data\n",
    "\n",
    "x_train, y_train = tf.cast(x_train/255., dtype=tf.float32), tf.cast(y_train/255., tf.float32)\n",
    "x_test, y_test = tf.cast(x_test/255., dtype=tf.float32), tf.cast(y_test/255., tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Dataset to represent an input Pipline\n",
    "\n",
    "# https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays\n",
    "ds_train = tf.data.Dataset.from_tensor_slices( (x_train, y_train) ).batch(32).shuffle(8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.ShuffleDataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(lambda x, y: (tf.image.random_flip_left_right(x), y))   # 隨機水平翻轉影像，加強資料差異, 但標籤 y 不變"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.repeat()  #無限重複"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size).shuffle(8888)\n",
    "ds_test = ds_test.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    " tf.keras.layers.Flatten(),\n",
    " tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    " tf.keras.layers.Dropout(0.3),\n",
    " tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When passing an infinitely repeating dataset, you must specify the `steps_per_epoch` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-91baef5e26fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m       \u001b[0mreset_dataset_after_each_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m       steps_per_epoch = training_utils.infer_steps_for_dataset(\n\u001b[0;32m--> 136\u001b[0;31m           data, steps_per_epoch, epochs=epochs, steps_name=steps_name)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;31m# Convert to a format that supports `next(generator)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36minfer_steps_for_dataset\u001b[0;34m(dataset, steps, epochs, steps_name)\u001b[0m\n\u001b[1;32m   1530\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFINITE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m     raise ValueError('When passing an infinitely repeating dataset, you '\n\u001b[0;32m-> 1532\u001b[0;31m                      'must specify the `%s` argument.' % (steps_name,))\n\u001b[0m\u001b[1;32m   1533\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: When passing an infinitely repeating dataset, you must specify the `steps_per_epoch` argument."
     ]
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 08:22:15.498340 139871233808192 deprecation.py:323] From /root/miniconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0027 - accuracy: 0.0992\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 2.3112e-06 - accuracy: 0.0967\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 1.3742e-06 - accuracy: 0.0984\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 1.0828e-06 - accuracy: 0.0984\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 9.9699e-07 - accuracy: 0.0993\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 9.7028e-07 - accuracy: 0.0989\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 9.6041e-07 - accuracy: 0.0978\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 9.5795e-07 - accuracy: 0.0973\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 23s 13ms/step - loss: 9.5548e-07 - accuracy: 0.0960\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 9.5410e-07 - accuracy: 0.0984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f35f41ef9e8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(x_train) // batch_size\n",
    "\n",
    "model.fit(ds_train, epochs=epochs, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 56ms/step - loss: 9.5367e-07 - accuracy: 0.0656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.536738616588991e-07, 0.065625]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage of Callback\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "callbacks = [\n",
    "  # Write TensorBoard logs to log_dir directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./tflog/{}'.format(dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 9.5387e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 44s 23ms/step - loss: 9.5391e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 44s 24ms/step - loss: 9.5398e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 9.5373e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 9.5369e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 9.5380e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 9.5373e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 9.5445e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 9.5372e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 25s 14ms/step - loss: 9.5370e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 9.5369e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 23s 13ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 9.5373e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 46s 25ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 40s 22ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 9.5368e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 9.5367e-07 - accuracy: 0.0987 - val_loss: 9.5367e-07 - val_accuracy: 0.0729\n",
      "Epoch 62/100\n",
      "1580/1875 [========================>.....] - ETA: 6s - loss: 9.5379e-07 - accuracy: 0.0999"
     ]
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "          validation_data=ds_test,\n",
    "          validation_steps=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(ds_test,steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.115625]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test,steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
